{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# https://towardsdatascience.com/beginners-guide-to-loading-image-data-with-pytorch-289c60b7afec\n",
    "# β-VAE: https://github.com/1Konny/Beta-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def pil_loader_rgba(path: str) -> Image.Image:\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        img = img.convert('RGBA')  # force alpha channel\n",
    "        background = Image.new('RGBA', img.size, (255, 255, 255))\n",
    "        alpha_composite = Image.alpha_composite(background, img).convert('RGB')\n",
    "    return alpha_composite\n",
    "\n",
    "# 图像增强：https://pytorch.org/vision/main/auto_examples/plot_transforms.html#random-transforms\n",
    "transform = T.Compose([T.Resize((128, 128)),\n",
    "                       T.RandomInvert(p=1),\n",
    "                       T.RandomHorizontalFlip(),\n",
    "                       T.RandomAffine(degrees=0, translate=(0.1,0.1), interpolation=T.InterpolationMode.BILINEAR),\n",
    "                       T.RandomInvert(p=1),\n",
    "                       #T.ColorJitter(hue=0.5, saturation=0.1, contrast=0.2),\n",
    "                       T.ToTensor()])\n",
    "'''transform = T.Compose([T.Resize((256, 256)),\n",
    "                       T.ToTensor()])'''\n",
    "\n",
    "img = ImageFolder(root='dataset', loader = pil_loader_rgba, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "for i in [16, 17, 18, 19]:\n",
    "    ax = plt.subplot(221 + i - 16)\n",
    "    arr, cls = img[i]\n",
    "\n",
    "    plt.imshow(arr.transpose(0,-1).transpose(0,1), vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import BetaVAE_H as VAE\n",
    "from Solver import reconstruction_loss, kl_divergence\n",
    "\n",
    "model = VAE(nc=3)\n",
    "model.eval()\n",
    "\n",
    "xrecon, mu, logvar = model(arr.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import copy\n",
    "\n",
    "class Reporter:\n",
    "    def __init__(self, dt, local=False):\n",
    "        self.dt = dt\n",
    "        self.loss_count = {}\n",
    "        self.k = 0.0\n",
    "        self.local = local\n",
    "        self.record = []\n",
    "    \n",
    "    def report(self):\n",
    "        if self.k > 0:\n",
    "            for k in self.loss_count.keys():\n",
    "                self.loss_count[k] /= self.k\n",
    "            if self.local:\n",
    "                self.record.append(copy.deepcopy(self.loss_count))\n",
    "                for k,v in self.loss_count.items():\n",
    "                    print(f'{k}: {v}', end='; ')\n",
    "                print('.')\n",
    "            else:\n",
    "                wandb.log(self.loss_count)\n",
    "    \n",
    "    def step(self, loss_dict):\n",
    "        self.k += 1\n",
    "        for k, v in loss_dict.items():\n",
    "            if not (k in self.loss_count):\n",
    "                self.loss_count[k] = 0.0\n",
    "            self.loss_count[k] += v\n",
    "        if self.k >= self.dt:\n",
    "            self.report()\n",
    "            self.k = 0\n",
    "            for k in self.loss_count.keys():\n",
    "                self.loss_count[k] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 5; lr=1e-3; dim=64\n",
    "\n",
    "wandb.init(config={'beta':beta, 'lr':lr, 'dim':dim}, project=\"Genshin VAE\")  # upload args\n",
    "\n",
    "gidata = data.DataLoader(img, batch_size=16, shuffle=True)\n",
    "model = VAE(nc=3, z_dim=dim)\n",
    "model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "reporter = Reporter(dt=10)\n",
    "\n",
    "def max_weight(model):\n",
    "    max_ = -1\n",
    "    for para in model.parameters():\n",
    "        para_max = max(abs(para)).item()\n",
    "        if para_max > max_:\n",
    "            max_ = para_max\n",
    "    return max_\n",
    "\n",
    "for i in range(10000):\n",
    "    loss_count = 0\n",
    "    k = 0\n",
    "    for x, cls in gidata:\n",
    "        optimizer.zero_grad()\n",
    "        x = x.cuda()\n",
    "        xrecon, mu, logvar = model(x)\n",
    "        rec_loss = reconstruction_loss(x, xrecon, distribution='gaussian')\n",
    "        total_kld, dimension_wise_kld, mean_kld = kl_divergence(mu, logvar)\n",
    "\n",
    "        loss = rec_loss + beta * total_kld\n",
    "        loss_count += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        reporter.step({'epco':i+k/len(gidata), 'loss':loss.item(), 'loss_rec':rec_loss.item(), 'kld':total_kld.item(), 'max_w':max_weight(model)})\n",
    "        k += 1\n",
    "    if i % 1000 == 0:\n",
    "        torch.save(model, f'./models/model_{i}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.1351,  0.2457,  0.0470, -0.0712],\n",
      "          [-0.0396,  0.0321, -0.0349,  0.0991],\n",
      "          [ 0.4036, -0.2128,  0.0321,  0.1213],\n",
      "          [-0.0840,  0.0621, -0.3310, -0.3118]],\n",
      "\n",
      "         [[ 0.2368, -0.2397, -0.0726,  0.0765],\n",
      "          [ 0.1789,  0.0852,  0.0208,  0.0166],\n",
      "          [-0.1838, -0.4289, -0.0909, -0.0076],\n",
      "          [-0.0275, -0.1189,  0.2796, -0.1264]],\n",
      "\n",
      "         [[-0.1004, -0.0921,  0.1749,  0.0333],\n",
      "          [-0.1626, -0.1281, -0.1731,  0.2038],\n",
      "          [ 0.0268, -0.0474,  0.1778, -0.1087],\n",
      "          [-0.2194,  0.1509,  0.2749, -0.2196]]],\n",
      "\n",
      "\n",
      "        [[[-0.1895, -0.0515,  0.1415,  0.2240],\n",
      "          [ 0.4438, -0.2663, -0.1410,  0.0297],\n",
      "          [ 0.4714,  0.0717,  0.2180,  0.0187],\n",
      "          [-0.0660,  0.3439,  0.4332, -0.0726]],\n",
      "\n",
      "         [[ 0.1908, -0.1847, -0.0679,  0.2698],\n",
      "          [-0.3016,  0.0480,  0.2567,  0.0652],\n",
      "          [-0.0749,  0.0280, -0.0883, -0.3398],\n",
      "          [ 0.2700, -0.3424,  0.0724, -0.3297]],\n",
      "\n",
      "         [[ 0.0154,  0.0673,  0.1052, -0.0231],\n",
      "          [-0.0840,  0.1351,  0.1442,  0.0221],\n",
      "          [-0.1285,  0.0122, -0.0404,  0.4277],\n",
      "          [ 0.2436,  0.0398, -0.2114,  0.1020]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3471,  0.0630, -0.3622, -0.5095],\n",
      "          [ 0.1409,  0.2288,  0.1246, -0.1956],\n",
      "          [-0.2962,  0.1339, -0.0682,  0.0543],\n",
      "          [-0.2981, -0.1448,  0.2348, -0.2418]],\n",
      "\n",
      "         [[-0.0190, -0.0505, -0.0346, -0.1145],\n",
      "          [ 0.1052,  0.2066,  0.0184,  0.0765],\n",
      "          [-0.0970,  0.1339, -0.0672,  0.0304],\n",
      "          [ 0.0104, -0.2780, -0.1564,  0.0313]],\n",
      "\n",
      "         [[ 0.2511,  0.0890, -0.4395,  0.0678],\n",
      "          [ 0.1946,  0.2453, -0.0216, -0.0855],\n",
      "          [-0.0493,  0.0499,  0.0039,  0.0406],\n",
      "          [ 0.4850, -0.0520,  0.2572, -0.0229]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1687,  0.2395,  0.0232, -0.1809],\n",
      "          [ 0.2652, -0.1766, -0.2531,  0.1572],\n",
      "          [ 0.0712, -0.0895, -0.2466,  0.0543],\n",
      "          [-0.1996,  0.1283,  0.1230, -0.1282]],\n",
      "\n",
      "         [[-0.1095, -0.1913, -0.1513,  0.1230],\n",
      "          [ 0.2562, -0.2041, -0.2787,  0.2115],\n",
      "          [ 0.1769,  0.2843, -0.2957,  0.3040],\n",
      "          [-0.2550, -0.0781,  0.4203,  0.2350]],\n",
      "\n",
      "         [[ 0.0980,  0.3603, -0.0103,  0.1331],\n",
      "          [ 0.1437, -0.0209,  0.2933, -0.0479],\n",
      "          [-0.1031, -0.1375,  0.0911, -0.0796],\n",
      "          [-0.2542,  0.2775, -0.0561,  0.1248]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0390,  0.0046,  0.1055, -0.1103],\n",
      "          [ 0.1679,  0.0381, -0.3759,  0.3261],\n",
      "          [ 0.1559,  0.1813,  0.3593, -0.4630],\n",
      "          [-0.1238,  0.0573,  0.2550,  0.0249]],\n",
      "\n",
      "         [[ 0.2423,  0.1346, -0.1606,  0.0476],\n",
      "          [-0.2295, -0.3072,  0.0363,  0.0444],\n",
      "          [-0.1602, -0.2313, -0.1412, -0.1871],\n",
      "          [-0.1444,  0.1745,  0.1038,  0.2220]],\n",
      "\n",
      "         [[-0.1074,  0.3525,  0.1516,  0.0595],\n",
      "          [ 0.3888,  0.1958, -0.1229,  0.0465],\n",
      "          [-0.3459, -0.3260,  0.1827,  0.1761],\n",
      "          [-0.0354,  0.2036,  0.0936, -0.1591]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0245,  0.2372,  0.1512,  0.2232],\n",
      "          [ 0.2647,  0.0924,  0.2068,  0.1994],\n",
      "          [-0.1082,  0.1368,  0.0335,  0.1321],\n",
      "          [-0.1448,  0.0929,  0.3730, -0.2111]],\n",
      "\n",
      "         [[-0.0714, -0.0706,  0.2470, -0.1864],\n",
      "          [-0.3775, -0.3044,  0.0935,  0.0313],\n",
      "          [-0.1486, -0.0233, -0.4663,  0.2488],\n",
      "          [-0.1430,  0.1144, -0.1461,  0.0771]],\n",
      "\n",
      "         [[-0.1370,  0.3515, -0.3755,  0.1316],\n",
      "          [-0.1251, -0.0148,  0.1309, -0.1086],\n",
      "          [ 0.0867,  0.0649,  0.0078, -0.0139],\n",
      "          [ 0.1140,  0.0296, -0.0547,  0.0992]]]], device='cuda:0',\n",
      "       requires_grad=True)"
     ]
    }
   ],
   "source": [
    "model.encoder[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.1351, 0.2457, 0.0470, 0.0712],\n",
      "          [0.0396, 0.0321, 0.0349, 0.0991],\n",
      "          [0.4036, 0.2128, 0.0321, 0.1213],\n",
      "          [0.0840, 0.0621, 0.3310, 0.3118]],\n",
      "\n",
      "         [[0.2368, 0.2397, 0.0726, 0.0765],\n",
      "          [0.1789, 0.0852, 0.0208, 0.0166],\n",
      "          [0.1838, 0.4289, 0.0909, 0.0076],\n",
      "          [0.0275, 0.1189, 0.2796, 0.1264]],\n",
      "\n",
      "         [[0.1004, 0.0921, 0.1749, 0.0333],\n",
      "          [0.1626, 0.1281, 0.1731, 0.2038],\n",
      "          [0.0268, 0.0474, 0.1778, 0.1087],\n",
      "          [0.2194, 0.1509, 0.2749, 0.2196]]],\n",
      "\n",
      "\n",
      "        [[[0.1895, 0.0515, 0.1415, 0.2240],\n",
      "          [0.4438, 0.2663, 0.1410, 0.0297],\n",
      "          [0.4714, 0.0717, 0.2180, 0.0187],\n",
      "          [0.0660, 0.3439, 0.4332, 0.0726]],\n",
      "\n",
      "         [[0.1908, 0.1847, 0.0679, 0.2698],\n",
      "          [0.3016, 0.0480, 0.2567, 0.0652],\n",
      "          [0.0749, 0.0280, 0.0883, 0.3398],\n",
      "          [0.2700, 0.3424, 0.0724, 0.3297]],\n",
      "\n",
      "         [[0.0154, 0.0673, 0.1052, 0.0231],\n",
      "          [0.0840, 0.1351, 0.1442, 0.0221],\n",
      "          [0.1285, 0.0122, 0.0404, 0.4277],\n",
      "          [0.2436, 0.0398, 0.2114, 0.1020]]],\n",
      "\n",
      "\n",
      "        [[[0.3471, 0.0630, 0.3622, 0.5095],\n",
      "          [0.1409, 0.2288, 0.1246, 0.1956],\n",
      "          [0.2962, 0.1339, 0.0682, 0.0543],\n",
      "          [0.2981, 0.1448, 0.2348, 0.2418]],\n",
      "\n",
      "         [[0.0190, 0.0505, 0.0346, 0.1145],\n",
      "          [0.1052, 0.2066, 0.0184, 0.0765],\n",
      "          [0.0970, 0.1339, 0.0672, 0.0304],\n",
      "          [0.0104, 0.2780, 0.1564, 0.0313]],\n",
      "\n",
      "         [[0.2511, 0.0890, 0.4395, 0.0678],\n",
      "          [0.1946, 0.2453, 0.0216, 0.0855],\n",
      "          [0.0493, 0.0499, 0.0039, 0.0406],\n",
      "          [0.4850, 0.0520, 0.2572, 0.0229]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.1687, 0.2395, 0.0232, 0.1809],\n",
      "          [0.2652, 0.1766, 0.2531, 0.1572],\n",
      "          [0.0712, 0.0895, 0.2466, 0.0543],\n",
      "          [0.1996, 0.1283, 0.1230, 0.1282]],\n",
      "\n",
      "         [[0.1095, 0.1913, 0.1513, 0.1230],\n",
      "          [0.2562, 0.2041, 0.2787, 0.2115],\n",
      "          [0.1769, 0.2843, 0.2957, 0.3040],\n",
      "          [0.2550, 0.0781, 0.4203, 0.2350]],\n",
      "\n",
      "         [[0.0980, 0.3603, 0.0103, 0.1331],\n",
      "          [0.1437, 0.0209, 0.2933, 0.0479],\n",
      "          [0.1031, 0.1375, 0.0911, 0.0796],\n",
      "          [0.2542, 0.2775, 0.0561, 0.1248]]],\n",
      "\n",
      "\n",
      "        [[[0.0390, 0.0046, 0.1055, 0.1103],\n",
      "          [0.1679, 0.0381, 0.3759, 0.3261],\n",
      "          [0.1559, 0.1813, 0.3593, 0.4630],\n",
      "          [0.1238, 0.0573, 0.2550, 0.0249]],\n",
      "\n",
      "         [[0.2423, 0.1346, 0.1606, 0.0476],\n",
      "          [0.2295, 0.3072, 0.0363, 0.0444],\n",
      "          [0.1602, 0.2313, 0.1412, 0.1871],\n",
      "          [0.1444, 0.1745, 0.1038, 0.2220]],\n",
      "\n",
      "         [[0.1074, 0.3525, 0.1516, 0.0595],\n",
      "          [0.3888, 0.1958, 0.1229, 0.0465],\n",
      "          [0.3459, 0.3260, 0.1827, 0.1761],\n",
      "          [0.0354, 0.2036, 0.0936, 0.1591]]],\n",
      "\n",
      "\n",
      "        [[[0.0245, 0.2372, 0.1512, 0.2232],\n",
      "          [0.2647, 0.0924, 0.2068, 0.1994],\n",
      "          [0.1082, 0.1368, 0.0335, 0.1321],\n",
      "          [0.1448, 0.0929, 0.3730, 0.2111]],\n",
      "\n",
      "         [[0.0714, 0.0706, 0.2470, 0.1864],\n",
      "          [0.3775, 0.3044, 0.0935, 0.0313],\n",
      "          [0.1486, 0.0233, 0.4663, 0.2488],\n",
      "          [0.1430, 0.1144, 0.1461, 0.0771]],\n",
      "\n",
      "         [[0.1370, 0.3515, 0.3755, 0.1316],\n",
      "          [0.1251, 0.0148, 0.1309, 0.1086],\n",
      "          [0.0867, 0.0649, 0.0078, 0.0139],\n",
      "          [0.1140, 0.0296, 0.0547, 0.0992]]]], device='cuda:0',\n",
      "       grad_fn=<AbsBackward>)"
     ]
    }
   ],
   "source": [
    "abs(model.encoder[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(abs(model.encoder[0].weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 5; lr=1e-3; dim=64\n",
    "\n",
    "wandb.init(config={'beta':beta, 'lr':lr, 'dim':dim}, project=\"Genshin VAE\")  # upload args\n",
    "\n",
    "gidata = data.DataLoader(img, batch_size=16, shuffle=True)\n",
    "model = VAE(nc=3, z_dim=dim)\n",
    "model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "reporter = Reporter(dt=10)\n",
    "\n",
    "def max_weight(model):\n",
    "    max_ = -1\n",
    "    for para in model.parameters():\n",
    "        para_max = abs(para.data).max().item()\n",
    "        if para_max > max_:\n",
    "            max_ = para_max\n",
    "    return max_\n",
    "\n",
    "for i in range(10000):\n",
    "    loss_count = 0\n",
    "    k = 0\n",
    "    for x, cls in gidata:\n",
    "        optimizer.zero_grad()\n",
    "        x = x.cuda()\n",
    "        xrecon, mu, logvar = model(x)\n",
    "        rec_loss = reconstruction_loss(x, xrecon, distribution='gaussian')\n",
    "        total_kld, dimension_wise_kld, mean_kld = kl_divergence(mu, logvar)\n",
    "\n",
    "        loss = rec_loss + beta * total_kld\n",
    "        loss_count += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        reporter.step({'epco':i+k/len(gidata), 'loss':loss.item(), 'loss_rec':rec_loss.item(), 'kld':total_kld.item(), 'max_w':max_weight(model)})\n",
    "        k += 1\n",
    "    if i % 1000 == 0:\n",
    "        torch.save(model, f'./models/model_{i}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
